{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bronze Ingestion\n",
    "\n",
    "### Spark Session Initialization\n",
    "\n",
    "This section initializes a Spark session configured with Delta Lake support."
   ],
   "id": "c423e6c2a1dbfdbe"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-14T23:50:02.479118Z",
     "start_time": "2026-01-14T23:50:00.271486Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "builder = SparkSession.builder.appName(\"Bronze Ingestion\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/01/15 00:50:00 WARN Utils: Your hostname, Henris-Mac.local, resolves to a loopback address: 127.0.0.1; using 192.168.100.227 instead (on interface en0)\n",
      "26/01/15 00:50:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Users/user1/spark-env/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /Users/user1/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /Users/user1/.ivy2.5.2/jars\n",
      "io.delta#delta-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-6318eaf5-85d1-4089-b88f-cb8743e53fd7;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.13;4.0.1 in central\n",
      "\tfound io.delta#delta-storage;4.0.1 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.13.1 in central\n",
      ":: resolution report :: resolve 55ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.13;4.0.1 from central in [default]\n",
      "\tio.delta#delta-storage;4.0.1 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.13.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-6318eaf5-85d1-4089-b88f-cb8743e53fd7\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
      "26/01/15 00:50:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/15 00:50:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "26/01/15 00:50:01 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Raw Data Configuration\n",
    "\n",
    "Define the base path for the raw source files.\n",
    "This layer represents the **Bronze layer**, where data is ingested in its original format with minimal transformation."
   ],
   "id": "faacaac13f45ca0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T23:50:02.487237Z",
     "start_time": "2026-01-14T23:50:02.483554Z"
    }
   },
   "cell_type": "code",
   "source": "raw_data = '../data/raw_csvs'",
   "id": "bbaaf2df1d954372",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Source Data Ingestion\n",
    "\n",
    "Load source datasets from CSV files into Spark DataFrames.\n",
    "Schemas are inferred automatically to simplify ingestion at the Bronze layer."
   ],
   "id": "fa46d99d03eae369"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T23:50:05.276329Z",
     "start_time": "2026-01-14T23:50:02.487598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "orders_df = (\n",
    "    spark.read\n",
    "         .csv(f\"{raw_data}/olist_orders_dataset.csv\",\n",
    "            header=True,\n",
    "            inferSchema=True)\n",
    ")\n",
    "\n",
    "customers_df = (\n",
    "    spark.read\n",
    "        .csv(f\"{raw_data}/olist_customers_dataset.csv\",\n",
    "            header=True,\n",
    "            inferSchema=True)\n",
    ")\n",
    "\n",
    "order_items_df = (\n",
    "    spark.read\n",
    "        .csv(f\"{raw_data}/olist_order_items_dataset.csv\",\n",
    "            header=True,\n",
    "            inferSchema=True)\n",
    ")\n",
    "\n",
    "order_payments_df = (\n",
    "    spark.read\n",
    "    .csv(f\"{raw_data}/olist_order_payments_dataset.csv\",\n",
    "        header=True,\n",
    "        inferSchema=True)\n",
    ")\n",
    "\n",
    "order_reviews_df = (\n",
    "    spark.read\n",
    "    .csv(f\"{raw_data}/olist_order_reviews_dataset.csv\",\n",
    "         header=True,\n",
    "         inferSchema=True)\n",
    ")\n",
    "\n",
    "products_df = (\n",
    "    spark.read\n",
    "    .csv(f\"{raw_data}/olist_products_dataset.csv\",\n",
    "         header=True,\n",
    "         inferSchema=True)\n",
    ")\n",
    "\n",
    "sellers_df = (\n",
    "    spark.read\n",
    "    .csv(f\"{raw_data}/olist_sellers_dataset.csv\",\n",
    "         header=True,\n",
    "         inferSchema=True)\n",
    ")"
   ],
   "id": "cb05ee939f731e71",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Validation\n",
    "\n",
    "Perform an initial inspection of the ingested datasets to validate structure and data types."
   ],
   "id": "b7604631c961dd37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T23:50:05.332272Z",
     "start_time": "2026-01-14T23:50:05.317434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Orders DF:')\n",
    "orders_df.printSchema()\n",
    "print('Customers DF:')\n",
    "customers_df.printSchema()"
   ],
   "id": "1408d3807b1c2540",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders DF:\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- order_purchase_timestamp: timestamp (nullable = true)\n",
      " |-- order_approved_at: timestamp (nullable = true)\n",
      " |-- order_delivered_carrier_date: timestamp (nullable = true)\n",
      " |-- order_delivered_customer_date: timestamp (nullable = true)\n",
      " |-- order_estimated_delivery_date: timestamp (nullable = true)\n",
      "\n",
      "Customers DF:\n",
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- customer_unique_id: string (nullable = true)\n",
      " |-- customer_zip_code_prefix: integer (nullable = true)\n",
      " |-- customer_city: string (nullable = true)\n",
      " |-- customer_state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T23:50:05.342279Z",
     "start_time": "2026-01-14T23:50:05.332628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Order items DF:')\n",
    "order_items_df.printSchema()\n",
    "print('Order payments DF:')\n",
    "order_payments_df.printSchema()"
   ],
   "id": "94cf2fc7d904740a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order items DF:\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- order_item_id: integer (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- seller_id: string (nullable = true)\n",
      " |-- shipping_limit_date: timestamp (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- freight_value: double (nullable = true)\n",
      "\n",
      "Order payments DF:\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- payment_sequential: integer (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- payment_installments: integer (nullable = true)\n",
      " |-- payment_value: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T23:50:05.352018Z",
     "start_time": "2026-01-14T23:50:05.342592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Order reviews DF:')\n",
    "order_reviews_df.printSchema()\n",
    "print('Products DF:')\n",
    "products_df.printSchema()\n",
    "print('Sellers DF:')\n",
    "sellers_df.printSchema()"
   ],
   "id": "b0580b4906294ec2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order reviews DF:\n",
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- review_score: string (nullable = true)\n",
      " |-- review_comment_title: string (nullable = true)\n",
      " |-- review_comment_message: string (nullable = true)\n",
      " |-- review_creation_date: string (nullable = true)\n",
      " |-- review_answer_timestamp: string (nullable = true)\n",
      "\n",
      "Products DF:\n",
      "root\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_category_name: string (nullable = true)\n",
      " |-- product_name_lenght: integer (nullable = true)\n",
      " |-- product_description_lenght: integer (nullable = true)\n",
      " |-- product_photos_qty: integer (nullable = true)\n",
      " |-- product_weight_g: integer (nullable = true)\n",
      " |-- product_length_cm: integer (nullable = true)\n",
      " |-- product_height_cm: integer (nullable = true)\n",
      " |-- product_width_cm: integer (nullable = true)\n",
      "\n",
      "Sellers DF:\n",
      "root\n",
      " |-- seller_id: string (nullable = true)\n",
      " |-- seller_zip_code_prefix: integer (nullable = true)\n",
      " |-- seller_city: string (nullable = true)\n",
      " |-- seller_state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Partitioning Strategy\n",
    "\n",
    "Partitioning is applied to optimize storage layout and query performance."
   ],
   "id": "a9bdf7801292b48c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T23:50:05.379050Z",
     "start_time": "2026-01-14T23:50:05.352376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "orders_df = (\n",
    "    orders_df\n",
    "        .withColumn(\"year\", F.year(\"order_purchase_timestamp\"))\n",
    "        .withColumn(\"month\", F.month(\"order_purchase_timestamp\"))\n",
    "        .withColumn(\"day\", F.dayofmonth(\"order_purchase_timestamp\"))\n",
    ")\n",
    "order_items_df = (\n",
    "    order_items_df\n",
    "    .withColumn(\"year\", F.year(\"shipping_limit_date\"))\n",
    "    .withColumn(\"month\", F.month(\"shipping_limit_date\"))\n",
    "    .withColumn(\"day\", F.day(\"shipping_limit_date\"))\n",
    ")"
   ],
   "id": "cf94adc12d48ea31",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Init the variale for the path to the bronze layer.",
   "id": "9aa21d4768c2acba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T23:50:05.441706Z",
     "start_time": "2026-01-14T23:50:05.379781Z"
    }
   },
   "cell_type": "code",
   "source": "bronze = '../delta/01_bronze'",
   "id": "6f868f879241c58b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Bronze Layer Completion\n",
    "\n",
    "The two tables with partition are done separately from the others, because they are more likely to produce errors. This way we can debug easier."
   ],
   "id": "20e22c062d2aa212"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T23:50:15.617387Z",
     "start_time": "2026-01-14T23:50:05.510432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(\n",
    "    orders_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .partitionBy(\"year\", \"month\", \"day\")\n",
    "    .save(f\"{bronze}/orders\")\n",
    ")"
   ],
   "id": "dc620cbbffaef9a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/15 00:50:05 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T23:50:19.870993Z",
     "start_time": "2026-01-14T23:50:15.625624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(\n",
    "    order_items_df.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .partitionBy(\"year\", \"month\", \"day\")\n",
    "            .save(f\"{bronze}/order_items\")\n",
    ")"
   ],
   "id": "35f9ac69018319f5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T23:50:24.622857Z",
     "start_time": "2026-01-14T23:50:19.876487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(\n",
    "    customers_df.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .save(f\"{bronze}/customers\")\n",
    ")\n",
    "\n",
    "(\n",
    "    order_payments_df.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .save(f\"{bronze}/order_payments\")\n",
    ")\n",
    "\n",
    "(\n",
    "    order_reviews_df.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .save(f\"{bronze}/order_reviews\")\n",
    ")\n",
    "\n",
    "(\n",
    "    products_df.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .save(f\"{bronze}/products\")\n",
    ")\n",
    "\n",
    "(\n",
    "    sellers_df.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .save(f\"{bronze}/sellers\")\n",
    ")"
   ],
   "id": "e76e9759634567d3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The Bronze ingestion process is complete.\n",
    "All raw datasets are now stored as Delta tables and are ready for cleansing and transformation in the Silver layer."
   ],
   "id": "91c0a30fe985fc6b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
